{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9c903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c5f56",
   "metadata": {},
   "source": [
    "### Pizza or Not Pizza:\n",
    "\n",
    "Using Inception V3 trained on imagenet, and the Kaggle dataset \"Pizza or Not Pizza\": https://www.kaggle.com/datasets/carlosrunner/pizza-not-pizza, I made a binary classifier that takes in an image and reports whether the image is of pizza or not. The data is roughly 2000 images, half of pizza and half of other foods. The data is images of different sizes, so I do some preprocessing to resize all images to 512x512 pixels. I create training, validation, and test data generators, and feed these into the model. Initially, the model was trained on just the softmax and dense layer added on top of Inception. I then trained again after unfreezing the top two layers of Inception. These models are \"PizzaOne\" and \"PizzaTwo\" respectively. At the end is just some code to take in a new image and apply the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e05304",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/ryanflynn/Desktop/pizzaNotPizza/'\n",
    "input_shape = (512, 512, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7617bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1680 images belonging to 2 classes.\n",
      "Found 204 images belonging to 2 classes.\n",
      "Found 82 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## generate data using imageDataGenerator, will pull from train/validation/test folders\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Createtrain, validation and test generators\n",
    "batch_size = 32\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    os.path.join(data_dir, 'train'),\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    os.path.join(data_dir, 'valid'),\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    os.path.join(data_dir, 'test'),\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24f2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the InceptionV3 model, chop off the top layer\n",
    "base_model = InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=input_shape)\n",
    "\n",
    "## add pooling and dense fully connected layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a final dense layer with softmax activation for the number of classes (should be 2)\n",
    "n_classes = len(train_generator.class_indices)\n",
    "predictions = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the complete model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41af28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, now with early stoppping and the top two layers set to trainable\n",
    "for layer in base_model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88077d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - 889s 17s/step - loss: 0.2762 - accuracy: 0.9024 - val_loss: 1.2968 - val_accuracy: 0.9265\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 851s 16s/step - loss: 0.0879 - accuracy: 0.9690 - val_loss: 0.4819 - val_accuracy: 0.9265\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 840s 16s/step - loss: 0.0597 - accuracy: 0.9839 - val_loss: 0.3450 - val_accuracy: 0.9265\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 839s 16s/step - loss: 0.0520 - accuracy: 0.9792 - val_loss: 0.4141 - val_accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 917s 17s/step - loss: 0.0478 - accuracy: 0.9857 - val_loss: 0.3360 - val_accuracy: 0.9265\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 844s 16s/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.4614 - val_accuracy: 0.9363\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 822s 15s/step - loss: 0.0351 - accuracy: 0.9899 - val_loss: 0.2928 - val_accuracy: 0.9216\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 836s 16s/step - loss: 0.0432 - accuracy: 0.9869 - val_loss: 0.2109 - val_accuracy: 0.9461\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 848s 16s/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.4619 - val_accuracy: 0.9020\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 798s 15s/step - loss: 0.0324 - accuracy: 0.9827 - val_loss: 0.5640 - val_accuracy: 0.9265\n"
     ]
    }
   ],
   "source": [
    "## PizzaTwo\n",
    "early = EarlyStopping(monitor='val_loss', patience=2)\n",
    "checkpoint = ModelCheckpoint('PizzaTwo.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=[early, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3b58aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - 618s 12s/step - loss: 0.4364 - accuracy: 0.8470 - val_loss: 0.3261 - val_accuracy: 0.8873\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 607s 11s/step - loss: 0.1636 - accuracy: 0.9399 - val_loss: 0.2340 - val_accuracy: 0.9314\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 604s 11s/step - loss: 0.1188 - accuracy: 0.9571 - val_loss: 0.1853 - val_accuracy: 0.9363\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 608s 11s/step - loss: 0.1053 - accuracy: 0.9583 - val_loss: 0.1634 - val_accuracy: 0.9363\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 609s 11s/step - loss: 0.0960 - accuracy: 0.9607 - val_loss: 0.2123 - val_accuracy: 0.9265\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 635s 12s/step - loss: 0.0832 - accuracy: 0.9756 - val_loss: 0.2020 - val_accuracy: 0.9461\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 610s 11s/step - loss: 0.0918 - accuracy: 0.9631 - val_loss: 0.1827 - val_accuracy: 0.9608\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 606s 11s/step - loss: 0.0857 - accuracy: 0.9696 - val_loss: 0.2186 - val_accuracy: 0.9265\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 605s 11s/step - loss: 0.0872 - accuracy: 0.9673 - val_loss: 0.2018 - val_accuracy: 0.9412\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 607s 11s/step - loss: 0.0773 - accuracy: 0.9732 - val_loss: 0.2031 - val_accuracy: 0.9363\n"
     ]
    }
   ],
   "source": [
    "# Train the model for a number of epochs (PizzaOne)\n",
    "# Train only the top layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b7d3e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 31s 8s/step - loss: 0.1303 - accuracy: 0.9512\n",
      "Test accuracy: 0.9512194991111755\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3034ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pizzaOne.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d323c66",
   "metadata": {},
   "source": [
    "### Application\n",
    "\n",
    "Some code to take any new image and format it correctly to run the model on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5a437f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('pizzaTwo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ae2e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgName = 'calzone.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6c08c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    img = Image.open(img)\n",
    "    img = img.resize((512, 512))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)    \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e87712c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newImg = preprocess_image(imgName)\n",
    "probs = model.predict(newImg)\n",
    "np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c69a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
